{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9OC_h39ig4N",
        "outputId": "16105367-8aef-41e6-891b-3e358b0e198a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A software developer is someone who has a lot of experience with the Linux kernel. He's been working on Fedora for over 10 years and still runs an active role as CEO, but he says now that his current company will eventually work to run its own virtualization system from within systemd. His new job description reads like this: \"I'll be responsible in my spare time running various parts or processes inside /etc/initrd.\"\n",
            "The idea behind it was simple enough; if you want to use your initramfs (or whatever) directly outside of GNOME Shell then there are no problems at all! But what about using something else? Well I've seen some people say they don't know how much more complex things can get when one uses another\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "def generate_text(prompt, max_length=150, temperature=0.8, top_k=50, top_p=0.9, repetition_penalty=1.2):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        temperature=temperature,\n",
        "        top_k=top_k,\n",
        "        top_p=top_p,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "prompt = \"A software developer is someone who\"\n",
        "print(generate_text(prompt, max_length=150, temperature=0.9, top_k=50, top_p=0.95, repetition_penalty=1.2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YDXsLt_Wik5e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}